{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1dd55f04",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import glob\n",
                "import tiktoken\n",
                "import numpy as np\n",
                "from dotenv import load_dotenv\n",
                "from langchain_openai import OpenAIEmbeddings\n",
                "from langchain_chroma import Chroma\n",
                "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
                "from langchain_community.document_loaders import PyPDFLoader\n",
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "from sklearn.manifold import TSNE\n",
                "import plotly.graph_objects as go"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c481036a",
            "metadata": {},
            "outputs": [],
            "source": [
                "MODEL = \"gpt-4.1-nano\"\n",
                "db_name = \"vector_db\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4c097d18",
            "metadata": {},
            "outputs": [],
            "source": [
                "load_dotenv(override=True)\n",
                "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d3c794e7",
            "metadata": {},
            "outputs": [],
            "source": [
                "loader = PyPDFLoader(file_path=\"CleanCode.pdf\")\n",
                "docs = loader.load()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c6a30987",
            "metadata": {},
            "outputs": [],
            "source": [
                "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
                "chunks = text_splitter.split_documents(docs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b807dacc",
            "metadata": {},
            "outputs": [],
            "source": [
                "# embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
                "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6fd9d524",
            "metadata": {},
            "outputs": [],
            "source": [
                "if os.path.exists(db_name):\n",
                "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "14ac614e",
            "metadata": {},
            "outputs": [],
            "source": [
                "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
                "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e94cec55",
            "metadata": {},
            "outputs": [],
            "source": [
                "collection = vectorstore._collection\n",
                "count = collection.count()\n",
                "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
                "dimensions = len(sample_embedding)\n",
                "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b3f71e0e",
            "metadata": {},
            "outputs": [],
            "source": [
                "retriever = vectorstore.as_retriever()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4106c764",
            "metadata": {},
            "outputs": [],
            "source": [
                "llm = ChatOpenAI(temperature=0, model_name=MODEL)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "952846dd",
            "metadata": {},
            "outputs": [],
            "source": [
                "retriever.invoke(\"What are the core principles of Clean Code?\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "77b7b4a8",
            "metadata": {},
            "outputs": [],
            "source": [
                "SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
                "Answer strictly based on the provided documents. \n",
                "Do not hallucinate. If the information is not in the documents, state so. \n",
                "Keep responses concise, structured, and aligned with the documents content. \n",
                "Combine relevant facts across documents when needed.\n",
                "Context:\n",
                "{context}\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8382827b",
            "metadata": {},
            "outputs": [],
            "source": [
                "def answer_question(question: str, history):\n",
                "    docs = retriever.invoke(question)\n",
                "    print(docs)\n",
                "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
                "    system_prompt = SYSTEM_PROMPT_TEMPLATE.format(context=context)\n",
                "    response = llm.invoke([SystemMessage(content=system_prompt), HumanMessage(content=question)])\n",
                "    return response.content"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5d96105c",
            "metadata": {},
            "outputs": [],
            "source": [
                "gr.ChatInterface(answer_question).launch()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fcbfa4dd",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "mla-rag",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
